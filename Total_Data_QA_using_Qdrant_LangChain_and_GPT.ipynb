{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX4TgIIdyq9B",
        "outputId": "f4d00bec-cc40-4cca-c20b-418af8ea15a9"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install PyPDF2\n",
        "!pip install qdrant_client\n",
        "!pip install langchain_openai\n",
        "!pip install pypdf\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3ezUS6vRgonc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Qdrant\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from qdrant_client import QdrantClient,models\n",
        "from qdrant_client.http.models import PointStruct\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B_PBmG9A3NaC"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"]=\"\"\n",
        "os.environ[\"QDRANT_URL\"]=\"\"\n",
        "os.environ[\"COLLECTION_NAME\"]=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGF5A27Bm0KF",
        "outputId": "8d0d449a-93c5-47cc-8c5c-92f72c52d62c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create collection reponse: <qdrant_client.qdrant_client.QdrantClient object at 0x798dd76977c0>\n",
            "Collection info: status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=0 indexed_vectors_count=0 points_count=0 segments_count=2 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1536, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None) payload_schema={}\n",
            "('status', <CollectionStatus.GREEN: 'green'>)\n",
            "('optimizer_status', <OptimizersStatusOneOf.OK: 'ok'>)\n",
            "('vectors_count', 0)\n",
            "('indexed_vectors_count', 0)\n",
            "('points_count', 0)\n",
            "('segments_count', 2)\n",
            "('config', CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1536, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None))\n",
            "('payload_schema', {})\n"
          ]
        }
      ],
      "source": [
        "#create new cluseter in qdrant\n",
        "record=0\n",
        "\n",
        "connection = QdrantClient(\n",
        "    url=os.environ.get(\"QDRANT_URL\"),\n",
        "    api_key=\"\",\n",
        ")\n",
        "\n",
        "\n",
        "connection.recreate_collection(\n",
        "    collection_name=os.environ.get(\"COLLECTION_NAME\"),\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),\n",
        ")\n",
        "print(\"Create collection reponse:\", connection)\n",
        "\n",
        "info = connection.get_collection(collection_name=os.environ.get(\"COLLECTION_NAME\"))\n",
        "\n",
        "print(\"Collection info:\", info)\n",
        "for get_info in info:\n",
        "  print(get_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ipIZecilkqyJ"
      },
      "outputs": [],
      "source": [
        "def load_and_split_documents(filepath=\"baby.pdf\"):\n",
        "  loader = PyPDFLoader(filepath)\n",
        "  documents = loader.load()\n",
        "  text_splitter = CharacterTextSplitter(chunk_size=400, chunk_overlap=100)\n",
        "  return text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zZ7bYE9loH7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "djAEYH2ngPKH"
      },
      "outputs": [],
      "source": [
        "def get_embeddings():\n",
        "  return OpenAIEmbeddings(\n",
        "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        "    chunk_size=1\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZHnNBGTccG3O"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "def get_chat_model():\n",
        "  return ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dFuWNl7IAuO2"
      },
      "outputs": [],
      "source": [
        "def get_document_store(docs, embeddings):\n",
        "  upsert = Qdrant.from_documents(\n",
        "    docs,\n",
        "    embeddings,\n",
        "    url=os.environ.get(\"QDRANT_URL\"),\n",
        "    collection_name=os.environ.get(\"COLLECTION_NAME\"),\n",
        "    force_recreate=True,\n",
        "    api_key=\"\"\n",
        "  )\n",
        "  print(upsert)\n",
        "  return upsert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ebz24C41IOeF"
      },
      "outputs": [],
      "source": [
        "def ask_question_with_context(qa, question, chat_history):\n",
        "\n",
        "    query = \"\"\n",
        "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
        "    print(\"answer:\", result[\"answer\"])\n",
        "    chat_history = [(query, result[\"answer\"])]\n",
        "    return chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFunULPheYdK",
        "outputId": "c65039df-5cc2-415d-ecb7-f10a983d93f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<langchain_community.vectorstores.qdrant.Qdrant object at 0x798dd5d67250>\n",
            "you: 托嬰補助怎麼申請？\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "answer: 要申請托嬰補助，您需要準備以下文件：\n",
            "1. 未滿二歲兒童托育準公共化服務費用申報表。\n",
            "2. 申請人及兒童的身分證明文件。\n",
            "3. 簽訂的托育服務契約書。\n",
            "4. 申請人其中一方的郵局或金融機構帳戶封面影本。\n",
            "5. 其他證明文件，如低收入戶、中低收入戶、第二名以上子女等。\n",
            "\n",
            "您可以在托育事實發生後的15天內，郵寄或親自送交上述文件至托嬰中心或居家保母所屬的居家托育服務中心進行申請。如果對核定結果有疑義，您可以在處分書送達後的30天內提出申復。\n",
            "you: 誰可以申請托嬰補助？\n",
            "answer: 未滿2歲兒童托育補助的申請對象包括實際年齡未滿2歲的我國籍兒童，且符合以下情形：\n",
            "1. 委託人的幼兒完成出生登記或戶籍登記。\n",
            "2. 送托與政府簽約的公設民營托嬰中心、社區公共托育家園、私立托嬰中心或居家托育人員（保母）。\n",
            "3. 每週送托時數達30小時以上。\n",
            "4. 未領取育兒津貼。\n",
            "5. 未經政府公費安置。\n",
            "6. 不得指定一對一收托，但有特殊狀況的幼兒除外。\n",
            "you: q\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "\n",
        "    embeddings = get_embeddings()\n",
        "    docs = load_and_split_documents()\n",
        "    # print(docs, embeddings)\n",
        "    doc_store = get_document_store(docs, embeddings)\n",
        "    llm = get_chat_model()\n",
        "\n",
        "    qa = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=doc_store.as_retriever(),\n",
        "        return_source_documents=True,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    chat_history = []\n",
        "    while True:\n",
        "        query = input('you: ')\n",
        "        if query == 'q':\n",
        "            break\n",
        "        chat_history = ask_question_with_context(qa, query, chat_history)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
