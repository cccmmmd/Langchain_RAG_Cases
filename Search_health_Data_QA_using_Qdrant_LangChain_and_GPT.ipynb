{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX4TgIIdyq9B"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install PyPDF2\n",
        "!pip install qdrant_client\n",
        "!pip install langchain_openai\n",
        "!pip install pypdf\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3ezUS6vRgonc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Qdrant\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from qdrant_client import QdrantClient,models\n",
        "from qdrant_client.http.models import PointStruct\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B_PBmG9A3NaC"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"]=\"\"\n",
        "os.environ[\"QDRANT_URL\"]=\"\"\n",
        "os.environ[\"QDRANT_COLLECTION_NAME\"]=\"health_report\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGF5A27Bm0KF"
      },
      "outputs": [],
      "source": [
        "#create new cluseter in qdrant\n",
        "record=0\n",
        "\n",
        "connection = QdrantClient(\n",
        "    url=os.environ.get(\"QDRANT_URL\"),\n",
        "    api_key=\"\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "info = connection.get_collection(collection_name=os.environ.get(\"QDRANT_COLLECTION_NAME\"))\n",
        "\n",
        "print(\"Collection info:\", info)\n",
        "for get_info in info:\n",
        "  print(get_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "djAEYH2ngPKH"
      },
      "outputs": [],
      "source": [
        "def get_embeddings():\n",
        "  return OpenAIEmbeddings(\n",
        "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        "    chunk_size=1\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZHnNBGTccG3O"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "def get_chat_model():\n",
        "  return ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ebz24C41IOeF"
      },
      "outputs": [],
      "source": [
        "def ask_question_with_context(qa, question, chat_history):\n",
        "    chat_history = []\n",
        "    query = \"\"\n",
        "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
        "    print(\"answer:\", result[\"answer\"])\n",
        "    chat_history = [(query, result[\"answer\"])]\n",
        "    return chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFunULPheYdK",
        "outputId": "fe78a1d3-5f13-4174-d387-aa27008b30c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "you: 糖尿病患血糖控管不佳會造成那些併發症?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "answer: 糖尿病患血糖控制不佳可能會造成以下併發症：\n",
            "1. 心臟、血管病變：包括高血壓、心絞痛、心肌梗塞、腦中風等。\n",
            "2. 全身感染：例如泌尿道感染、肺結核、黴菌感染、香港腳、體癬、灰指甲、足癬、帶狀皰疹等。\n",
            "3. 神經病變：包括手腳酸麻、肌肉變形、足部變形等。\n",
            "這些併發症可能會導致嚴重的健康問題，因此重要控制血糖，以預防這些併發症的發生。\n",
            "you: 總膽固醇200mg/dl, 三酸甘油酯110mg/dl, 這樣算高血脂症嗎?\n",
            "answer: 根據衛教資料，總膽固醇理想濃度為＜200mg/dl，而三酸甘油酯的理想濃度為＜150mg/dl。根據你提供的數值，總膽固醇200mg/dl已達邊緣值，而三酸甘油酯110mg/dl在正常範圍內。因此，根據這些數據，你的總膽固醇已達邊緣值，建議密切注意飲食及生活習慣，以預防高血脂症的發展。\n",
            "you: 腦中風跟高血脂有關係嗎？\n",
            "answer: 腦中風與高血脂有關係。高血脂症會導致動脈粥樣硬化，也就是動脈壁上的脂肪堆積，進而造成血管阻塞或破裂，增加腦中風的風險。因此，控制高血脂可以降低罹患腦中風的機率。\n",
            "you: 健檢項目越多越好嗎？\n",
            "answer: 健檢項目的選擇應該是因人而異的，並不是越多越好。選擇適合自己的健檢項目才是最重要的。根據個人的年齡、性別、家族病史、生活環境、生活習慣等因素，尋找適合自己的健檢項目才能達到最佳效果。建議向專業的醫療團隊諮詢，找出符合自己需求的健檢項目。\n",
            "you: 如果我不控制三高，會發生什麼？\n",
            "answer: 如果您不控制三高（高血壓、高血脂、高血糖），可能會引發以下慢性併發症：\n",
            "\n",
            "1. 大血管病變：包括腦中風、心肌梗塞、週邊動脈狹窄等。\n",
            "2. 小血管病變：可能導致視網膜病變、腎臟病變等。\n",
            "3. 神經病變：可能出現手腳酸麻、肌肉變形、足部變形等症狀。\n",
            "\n",
            "因此，控制三高是非常重要的，可以透過飲食、運動、藥物等方式改善症狀，降低合併症的風險。如果有任何疑問或需要更詳細的建議，建議您咨詢醫師進行評估和治療。\n",
            "you: 患有三高的人應該遵循什麼飲食原則?\n",
            "answer: 患有三高的人應該遵循以下飲食原則：\n",
            "1. 採六大均衡飲食定時定量，選擇少油、少鹽、不加糖、不勾芡、多纖維食物。\n",
            "2. 控制油量攝取，少吃油炸、油煎或油酥的食物；少吃豬皮、雞皮、鴨皮、魚皮等。\n",
            "3. 炒菜宜選用不飽和脂肪酸高的油脂，如橄欖油、花生油、菜籽油、葵花油等，少用飽和脂肪酸高的動物油。\n",
            "4. 多食用高纖維食物，包括五榖根莖類、未加工的豆類、各類蔬菜和水果。\n",
            "5. 控制總脂肪攝取量，佔總熱量的20%~30%。\n",
            "6. 多攝取富含Omega-3脂肪酸的食物，如秋刀魚、鮭魚、鯖魚等。\n",
            "7. 避免大量飲酒或含酒精飲料。\n",
            "8. 如果對飲食控制有任何疑問，可以諮詢醫師或營養師。\n",
            "you: 有遺傳高血壓女性42歲,會生出有高血壓的嬰兒嗎? \n",
            "answer: 根據遺傳學的原理，父母有高血壓的遺傳風險會增加孩子患高血壓的可能性。如果母親有遺傳高血壓，生下的嬰兒可能會有較高的患高血壓的風險。然而，高血壓是受多種因素影響的疾病，包括基因、生活方式、環境等，因此並非所有遺傳高血壓的母親都會生出有高血壓的嬰兒。建議您在懷孕前向醫師諮詢，並在懷孕期間接受定期的產前檢查，以確保母子健康。\n",
            "you: 有沒有方法可預防嬰兒得遺傳高血壓?\n",
            "answer: 抱歉，我只能回答健康檢查、三高相關的問題，無法回答有關嬰兒遺傳高血壓的問題。如果有其他健康相關問題，歡迎提出。\n",
            "you: 健康檢查多久要做一次\n",
            "answer: 健康檢查的頻率建議因個人健康狀況而異。一般建議30歲起可以進行第一次全身健康檢查，40歲以上未滿65歲者，應該至少每2-3年接受一次健檢，並針對高風險項目持續追蹤，65歲以上則應該每年做一次檢查。然而，健康檢查的頻率沒有絕對的標準，主要還是依個人健康狀況與面臨的疾病風險而定。建議諮詢專業醫護人員以規劃適合的健康檢查計劃。\n",
            "you: 如果吃了降血壓的藥之後血壓恢復正常，是不是就可以不必再吃降血壓的藥了？\n",
            "answer: 不一定，即使血壓恢復正常，仍需要依照醫師的建議繼續服用降血壓藥物。停藥可能會導致血壓再次升高，增加器官損傷的風險。在醫師指導下，才能適時調整藥物劑量或考慮停藥。\n",
            "you: 長期吃降血壓的藥會不會有副作用？\n",
            "answer: 長期吃降血壓的藥物可能會有一些副作用，包括但不限於頭暈、疲倦、肌肉痠痛、頭痛、腹瀉、皮疹等。在使用降血壓藥物期間，應該密切注意身體狀況，並定期回診檢查以確保藥物的有效性和安全性。如果有任何不適或疑慮，應及時告知主治醫師。\n",
            "you: q\n"
          ]
        }
      ],
      "source": [
        "# from langchain.prompts import PromptTemplate\n",
        "from langchain_core.prompts import SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "def main():\n",
        "\n",
        "    embeddings = get_embeddings()\n",
        "\n",
        "    llm = get_chat_model()\n",
        "\n",
        "    vector_store = Qdrant(\n",
        "        client=connection,\n",
        "        collection_name=os.getenv(\"QDRANT_COLLECTION_NAME\"),\n",
        "        embeddings=embeddings,\n",
        "    )\n",
        "    system_template = \"\"\"你是只會用繁體中文的護士，只能回答健康檢查、三高有關的問題，其他問題一律不回答。必須只用繁體中文回答問題。\n",
        "        ----------------\n",
        "        {context}\"\"\"\n",
        "    messages = [\n",
        "        SystemMessagePromptTemplate.from_template(system_template),\n",
        "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "        ]\n",
        "    qa_prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "    qa = ConversationalRetrievalChain.from_llm(\n",
        "          llm=llm,\n",
        "          retriever=vector_store.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.7, \"k\": 3}),\n",
        "          return_source_documents=True,\n",
        "          condense_question_llm = llm,\n",
        "          combine_docs_chain_kwargs={\"prompt\": qa_prompt})\n",
        "\n",
        "    chat_history = []\n",
        "    while True:\n",
        "        query = input('you: ')\n",
        "        if query == 'q':\n",
        "            break\n",
        "        chat_history = ask_question_with_context(qa, query, chat_history)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
