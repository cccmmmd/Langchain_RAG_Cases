{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX4TgIIdyq9B"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install PyPDF2\n",
        "!pip install qdrant_client\n",
        "!pip install langchain_openai\n",
        "!pip install pypdf\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ezUS6vRgonc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Qdrant\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from qdrant_client import QdrantClient,models\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_PBmG9A3NaC"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"]=\"\"\n",
        "os.environ[\"QDRANT_URL\"]=\"\"\n",
        "os.environ[\"QDRANT_COLLECTION_NAME\"]=\"\"\n",
        "os.environ[\"QDRANT_API_KEY\"]=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGF5A27Bm0KF",
        "outputId": "38e5266a-fb14-420e-c291-8da73ebeed66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection info: status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=91 indexed_vectors_count=0 points_count=91 segments_count=2 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1536, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None) payload_schema={}\n",
            "('status', <CollectionStatus.GREEN: 'green'>)\n",
            "('optimizer_status', <OptimizersStatusOneOf.OK: 'ok'>)\n",
            "('vectors_count', 91)\n",
            "('indexed_vectors_count', 0)\n",
            "('points_count', 91)\n",
            "('segments_count', 2)\n",
            "('config', CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1536, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None))\n",
            "('payload_schema', {})\n"
          ]
        }
      ],
      "source": [
        "#create new cluseter in qdrant\n",
        "record=0\n",
        "\n",
        "connection = QdrantClient(\n",
        "    url=os.environ.get(\"QDRANT_URL\"),\n",
        "    api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "info = connection.get_collection(collection_name=os.environ.get(\"QDRANT_COLLECTION_NAME\"))\n",
        "\n",
        "print(\"Collection info:\", info)\n",
        "for get_info in info:\n",
        "  print(get_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djAEYH2ngPKH"
      },
      "outputs": [],
      "source": [
        "def get_embeddings():\n",
        "  return OpenAIEmbeddings(\n",
        "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        "    chunk_size=1\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHnNBGTccG3O"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "def get_chat_model():\n",
        "  return ChatOpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebz24C41IOeF"
      },
      "outputs": [],
      "source": [
        "def ask_question_with_context(qa, question, chat_history):\n",
        "\n",
        "    query = \"\"\n",
        "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
        "    print(\"answer:\", result[\"answer\"])\n",
        "    chat_history = [(query, result[\"answer\"])]\n",
        "    return chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFunULPheYdK",
        "outputId": "147ac72c-3a04-44be-c12f-639b0b16286c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "you: 什麼是低血壓\n",
            "answer: 低血壓是指血液在血管中流動時对血管壁施加的压力过低。通常，成年人的理想血压应该控制在舒张压低于80mmHg和舒张压低于120mmHg。低血压可能会导致头晕、乏力、虚弱等症状。\n",
            "you: q\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "def main():\n",
        "\n",
        "    embeddings = get_embeddings()\n",
        "\n",
        "    llm = get_chat_model()\n",
        "\n",
        "    vector_store = Qdrant(\n",
        "        client=connection,\n",
        "        collection_name=os.getenv(\"QDRANT_COLLECTION_NAME\"),\n",
        "        embeddings=embeddings,\n",
        "    )\n",
        "    QUESTION_PROMPT = PromptTemplate.from_template(\"\"\"你是護士，只能回答健康檢查的問題，其他問題一律不回答。並以繁體中文回答問題。\"\"\")\n",
        "\n",
        "    qa = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vector_store.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.7, \"k\": 3}),\n",
        "        return_source_documents=True,\n",
        "        condense_question_llm = llm,\n",
        "        condense_question_prompt=QUESTION_PROMPT,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "\n",
        "    chat_history = []\n",
        "    while True:\n",
        "        query = input('you: ')\n",
        "        if query == 'q':\n",
        "            break\n",
        "        chat_history = ask_question_with_context(qa, query, chat_history)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
